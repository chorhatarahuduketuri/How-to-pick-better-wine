{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "## How well can the quality of wine be predicted from physicochemical measurements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "red_wine = pd.read_csv('../data/winequality-red.csv', delimiter=';')\n",
    "white_wine = pd.read_csv('../data/winequality-white.csv', delimiter=';')\n",
    "\n",
    "red_x = red_wine.iloc[:,:11]\n",
    "red_y = red_wine.iloc[:,-1:]\n",
    "\n",
    "white_x = white_wine.iloc[:,:11]\n",
    "white_y = white_wine.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`winequality.names` in the `data` directory contains information on the datasets, including some concerning prior analyses, where SVMs achieved the best results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chhk/.local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# train/test split\n",
    "red_x_train, red_x_test, red_y_train, red_y_test = train_test_split(red_x, red_y, train_size=0.7)\n",
    "white_x_train, white_x_test, white_y_train, white_y_test = train_test_split(white_x, white_y, train_size=0.7, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean normalisation\n",
    "red_scaler = StandardScaler().fit(red_x_train)\n",
    "standardised_red_x_train = red_scaler.transform(red_x_train)\n",
    "standardised_red_x_test = red_scaler.transform(red_x_test)\n",
    "\n",
    "white_scaler = StandardScaler().fit(white_x_train)\n",
    "standardised_white_x_train = white_scaler.transform(white_x_train)\n",
    "standardised_white_x_test = white_scaler.transform(white_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red lr pred mae: 0.502297\n",
      "white lr pred mae: 0.587126\n"
     ]
    }
   ],
   "source": [
    "# obligatory linear regression \n",
    "red_lr = LinearRegression()\n",
    "red_lr.fit(standardised_red_x_train, red_y_train)\n",
    "red_lr_pred = red_lr.predict(standardised_red_x_test)\n",
    "print('red lr pred mae: %f' % mean_absolute_error(red_y_test, red_lr_pred))\n",
    "\n",
    "white_lr = LinearRegression()\n",
    "white_lr.fit(standardised_white_x_train, white_y_train)\n",
    "white_lr_pred = white_lr.predict(standardised_white_x_test)\n",
    "print('white lr pred mae: %f' % mean_absolute_error(white_y_test, white_lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae red svr poly: 0.529313\n",
      "mae red svr rbf: 0.453978\n",
      "mae red svr sigmoid: 5.844613\n"
     ]
    }
   ],
   "source": [
    "# red svr \n",
    "red_svr_ploy = SVR(kernel='poly')\n",
    "red_svr_rbf = SVR(kernel='rbf')\n",
    "red_svr_sigmoid = SVR(kernel='sigmoid')\n",
    "\n",
    "red_svr_ploy.fit(standardised_red_x_train, red_y_train.values.ravel())\n",
    "red_svr_rbf.fit(standardised_red_x_train, red_y_train.values.ravel())\n",
    "red_svr_sigmoid.fit(standardised_red_x_train, red_y_train.values.ravel())\n",
    "\n",
    "red_svr_poly_predictions = red_svr_ploy.predict(standardised_red_x_test)\n",
    "red_svr_rbf_predictions = red_svr_rbf.predict(standardised_red_x_test)\n",
    "red_svr_sigmoid_predictions = red_svr_sigmoid.predict(standardised_red_x_test)\n",
    "\n",
    "print('mae red svr poly: %f' % mean_absolute_error(red_y_test,red_svr_poly_predictions))\n",
    "print('mae red svr rbf: %f' % mean_absolute_error(red_y_test,red_svr_rbf_predictions))\n",
    "print('mae red svr sigmoid: %f' % mean_absolute_error(red_y_test,red_svr_sigmoid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae white svr poly: 0.661716\n",
      "mae white svr rbf: 0.514259\n",
      "mae white svr sigmoid: 14.632742\n"
     ]
    }
   ],
   "source": [
    "# white svr\n",
    "white_svr_ploy = SVR(kernel='poly')\n",
    "white_svr_rbf = SVR(kernel='rbf')\n",
    "white_svr_sigmoid = SVR(kernel='sigmoid')\n",
    "\n",
    "white_svr_ploy.fit(standardised_white_x_train, white_y_train.values.ravel())\n",
    "white_svr_rbf.fit(standardised_white_x_train, white_y_train.values.ravel())\n",
    "white_svr_sigmoid.fit(standardised_white_x_train, white_y_train.values.ravel())\n",
    "\n",
    "white_svr_poly_predictions = white_svr_ploy.predict(standardised_white_x_test)\n",
    "white_svr_rbf_predictions = white_svr_rbf.predict(standardised_white_x_test)\n",
    "white_svr_sigmoid_predictions = white_svr_sigmoid.predict(standardised_white_x_test)\n",
    "\n",
    "print('mae white svr poly: %f' % mean_absolute_error(white_y_test,white_svr_poly_predictions))\n",
    "print('mae white svr rbf: %f' % mean_absolute_error(white_y_test,white_svr_rbf_predictions))\n",
    "print('mae white svr sigmoid: %f' % mean_absolute_error(white_y_test,white_svr_sigmoid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both datasets the RBF kernel resulted in the most accurate predictions, so a gridsearch will be run to fine tune it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'C': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3,\n",
       "       1.4, 1.5, 1.6, 1.7, 1.8, 1.9]), 'gamma': array([0.01, 0.02, ..., 0.98, 0.99])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# svr gridsearches\n",
    "parameters = {'C':np.arange(0.1, 2.0, 0.1), 'gamma': np.arange(0.01, 1, 0.01)}\n",
    "\n",
    "red_rbf_gridsearchcv = GridSearchCV(SVR(kernel='rbf'), parameters, n_jobs=4)\n",
    "white_rbf_gridsearchcv = GridSearchCV(SVR(kernel='rbf'), parameters, n_jobs=4)\n",
    "\n",
    "red_rbf_gridsearchcv.fit(standardised_red_x_train, red_y_train.values.ravel())\n",
    "white_rbf_gridsearchcv.fit(standardised_white_x_train, white_y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red Wine:\n",
      "\tred rbf gridsearchCV best score: 0.365047\n",
      "\tred rbf gridsearchCV best params: {'C': 0.6, 'gamma': 0.060000000000000005}\n",
      "\n",
      "White Wine:\n",
      "\twhite rbf gridsearchCV best score: 0.382712\n",
      "\twhite rbf gridsearchCV best params: {'C': 1.4000000000000001, 'gamma': 0.15000000000000002}\n"
     ]
    }
   ],
   "source": [
    "print('Red Wine:')\n",
    "print('\\tred rbf gridsearchCV best score: %f' % red_rbf_gridsearchcv.best_score_)\n",
    "print('\\tred rbf gridsearchCV best params: %s' % red_rbf_gridsearchcv.best_params_)\n",
    "print()\n",
    "print('White Wine:')\n",
    "print('\\twhite rbf gridsearchCV best score: %f' % white_rbf_gridsearchcv.best_score_)\n",
    "print('\\twhite rbf gridsearchCV best params: %s' % white_rbf_gridsearchcv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the best SVM can get mean absolute error (which is a useful error measurement because it relates directly to the target variable which we understand intuitively) between 0.36 (for red wine) and 0.37 (for white wine.) \n",
    "\n",
    "Fortunately, that is better than default linear regression. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
